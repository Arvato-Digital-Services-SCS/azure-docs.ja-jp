---
title: データのインポート:モジュール リファレンス
titleSuffix: Azure Machine Learning service
description: Azure Machine Learning service のデータのインポート モジュールを使用し、既存のクラウド データ サービスのデータを機械学習パイプラインに読み込む方法を学習します。
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: xiaoharper
ms.author: zhanxia
ms.date: 05/02/2019
ms.openlocfilehash: fef7d686479b24b0402ab6f1e6990df74231b8d6
ms.sourcegitcommit: e0e6663a2d6672a9d916d64d14d63633934d2952
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 10/21/2019
ms.locfileid: "72693148"
---
# <a name="import-data-module"></a>データのインポート モジュール

この記事では、Azure Machine Learning service のビジュアル インターフェイス (プレビュー) のモジュールについて説明します。

このモジュールを使用し、既存のクラウド データ サービスのデータを機械学習パイプラインに読み込みます。  

最初に、読み込み元のクラウドベースのストレージの種類を選択し、追加の設定を完了します。 必要なデータを定義し、ソースに接続すると、[データのインポート](./import-data.md)では、列に含まれる値に基づいて各列のデータ型が推測され、Azure Machine Learning ワークスペースにデータが読み込まれます。 [データのインポート](./import-data.md)からは、あらゆるパイプラインで使用できるデータセットが出力されます。

  
ソース データが変更された場合、[データのインポート](./import-data.md)を再実行することでデータセットを更新し、新しいデータを追加できます。 ただし、パイプラインを実行するたびにソースから再び読み込むことを望まない場合、 **[Use cached results]\(キャッシュされた結果を使用する\)** オプションを TRUE に設定します。 このオプションを選択すると、このモジュールでは、同じソースと同じ入力オプションでパイプラインが前に実行されているかどうかが確認されます。 前の実行が見つかった場合、ソースからデータを再読み込みせず、キャッシュのデータが使用されます。
 

## <a name="data-sources"></a>データ ソース

データのインポート モジュールでは、次のデータ ソースがサポートされています。 リンクをクリックすると、各データ ソースの使用方法とサンプルが表示されます。 
 
データの保管方法や保管場所がわからない場合、データ サイエンス プロセスにおける一般的なデータ シナリオに関するガイド「[Azure Machine Learning での高度な分析のシナリオ](https://docs.microsoft.com/azure/machine-learning/machine-learning-data-science-plan-sample-scenarios)」を参照してください。 


|データ ソース| 用途|
|-----------|-----------|  
|[HTTP を使用する Web URL](./import-from-web-url-via-http.md)|HTTP を使用し、CSV、TSV、ARFF、または SvmLight 形式で指定されている Web URL でホストされているデータを取得する|  
|[Azure Blob Storage からのインポート](./import-from-azure-blob-storage.md) |Azure BLOB サービスに格納されているデータを取得する|  
|[Azure SQL Database からのインポート](./import-from-azure-sql-database.md) |Azure SQL Database からデータを取得する|

## <a name="how-to-configure-import-data"></a>データのインポートを構成する方法
 
1. **データのインポート** モジュールをパイプラインに追加します。 このモジュールは、インターフェイスの **[Data Input and Output]\(データの入力と出力\)** カテゴリにあります。

1. **[データ ソース]** をクリックし、読み込み元のクラウドベース ストレージの種類を選択します。 

    追加の設定は、選択したストレージの種類と、ストレージがセキュリティで保護されているかどうかに依存します。 場合によっては、アカウント名、ファイルの種類、資格情報を指定する必要があります。 一部のソースでは認証が要求されません。認証を必要とするソースの場合、アカウント名、キー、コンテナー名を把握しておく必要があります。

1. 後続の実行で再利用する目的でデータセットをキャッシュする場合、 **[Use cached results]\(キャッシュされた結果を使用する\)** オプションを選択します。

    モジュール パラメーターに他の変更がなければ、パイプラインでは、モジュールの初回実行時にのみデータが読み込まれ、その後はキャッシュしたデータセットが使用されます。

    パイプラインを実行するたびにデータを再読み込みする場合、このオプションの選択を解除してください。

1. パイプラインを実行します。

    データのインポートによりインターフェイスにデータが読み込まれるとき、列に含まれる値に基づいて各列のデータ型が推測されます。数値かカテゴリになります。

    - ヘッダーが存在する場合、出力されるデータセットの列に名前を付ける際、ヘッダーが使用されます。

    - データに既存の列ヘッダーがない場合、「col1, col2,…, coln*」の形式で新しい列に名前が付けられます。

## <a name="results"></a>結果

インポートが完了したら、出力されたデータセットをクリックし、 **[Visualize]\(視覚化\)** を選択し、データが正常にインポートされたかどうかを確認します。

パイプラインを実行するたびに新しいデータセットをインポートせず、再利用のためにデータを保存する場合、出力を右クリックし、 **[データセットとして保存]** を選択します。 データセットの名前を選択します。 保存されたデータセットには、保存時のデータが保持されています。パイプラインが再実行されたとき、パイプライン内のデータセットに変更があっても、データは更新されません。 データのスナップショットを作成する場合に便利です。

データのインポート後、モデル化と分析のために追加の準備が必要になることがあります。


- 列名を変更したり、列を別のデータ型として処理したり、一部の列がラベルまたはフィーチャーであることを指定したりするには、[メタデータの編集](./edit-metadata.md)を使用します。

- 変換する、またはモデル化で使用する列のサブセットを選択するには、[[データセット内の列の選択]](./select-columns-in-dataset.md) を使用します。 変換された列や削除された列は、[列の追加](./add-columns.md)モジュールを使用することで、元のデータセットに簡単に戻すことができます。  

- データセットを分割したり、サンプリングを実行したり、上位 n 行を取得したりするには、[[パーティションとサンプル]](./partition-and-sample.md) を使用します。

## <a name="next-steps"></a>次の手順

Azure Machine Learning service で[使用できる一連のモジュール](module-reference.md)を参照してください。 